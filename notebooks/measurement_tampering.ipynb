{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background / Intro\n",
    "\n",
    "This notebook trains a measurement predictor on trusted and untrusted data in the diamonds data-set\n",
    "trains a \"ground-truth\" probe using the ground truth diamond labels, and evaluates \n",
    "a \"confidence-based detector\" -using confidence in prediction of aggregated measurments\n",
    "as a detector for anomolous examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cupbearer import data, detectors, models, scripts, tasks, utils\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "import torch\n",
    "import submitit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_HPARAMS = {\n",
    "    \"model\": \"pythia-14m\",\n",
    "    \"batch_size_on_device\": 4,\n",
    "    \"num_epochs\": 1,\n",
    "    \"dataset_len\": 2,\n",
    "    \"slurm_params\": {}\n",
    "}\n",
    "REAL_HPARAMS = {\n",
    "    \"model\": \"code-gen\",\n",
    "    \"batch_size_on_device\": 4, \n",
    "    \"num_epochs\": 5, \n",
    "    \"dataset_len\": None,\n",
    "    \"slurm_params\": {\n",
    "        \"slurm_mem_gb\": 80, \n",
    "        \"gres\": \"gpu:A100-SXM4-80GB:1\",\n",
    "        \"nodes\": 1, \n",
    "        \"timeout_min\": 60 * 10,\n",
    "        \"job_name\": \"bash\",\n",
    "        \"qos\": \"high\"\n",
    "    }\n",
    "}\n",
    "\n",
    "HPARAMS = REAL_HPARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer, tokenizer, emb_dim, max_len = models.transformers_hf.load_transformer(\n",
    "    HPARAMS[\"model\"]\n",
    ")\n",
    "model = models.TamperingPredictionTransformer(\n",
    "        model=transformer,\n",
    "        embed_dim=emb_dim\n",
    "    )\n",
    "tokenizer = model.set_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.TamperingDataset(\"diamonds\", tokenizer=tokenizer, max_length=max_len, \n",
    "                                   train=True, dataset_len=HPARAMS[\"dataset_len\"])\n",
    "val_data = data.TamperingDataset(\"diamonds\", tokenizer=tokenizer, max_length=max_len, \n",
    "                                 train=False, dataset_len=HPARAMS[\"dataset_len\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Experiment Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = os.path.abspath(utils.log_path(\"logs/tampering/predictor\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Measurement Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import DeviceStatsMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_dir = os.path.join(exp_dir, \"train_pred\")\n",
    "os.makedirs(train_pred_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-5\n",
    "weight_decay = 2e-2\n",
    "num_warmup_steps = 64\n",
    "batch_size_base = 32\n",
    "precision=\"16-mixed\"\n",
    "\n",
    "batch_size_on_device = HPARAMS[\"batch_size_on_device\"]\n",
    "accumulate_grad_batches = batch_size_base // batch_size_on_device\n",
    "num_epochs = HPARAMS[\"num_epochs\"]\n",
    "loss_weights = [0.7, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size_on_device, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size_on_device, shuffle=False)\n",
    "total_steps = num_epochs * len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = lambda logits, labels: \\\n",
    "    torch.nn.functional.binary_cross_entropy_with_logits(logits[:, :3], labels[:, :3]) * loss_weights[0] + \\\n",
    "    torch.nn.functional.binary_cross_entropy_with_logits(logits[:, 3], labels[:, 3]) * loss_weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = submitit.AutoExecutor(folder=train_pred_dir)\n",
    "executor.update_parameters(**HPARAMS[\"slurm_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = executor.submit(scripts.train_classifier,\n",
    "    path=exp_dir,\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    task=\"multilabel\",\n",
    "    num_labels=4,\n",
    "    val_loaders=val_loader,\n",
    "    optim_builder=torch.optim.AdamW,\n",
    "    optim_conf={\"lr\": lr, \"weight_decay\": weight_decay},\n",
    "    lr_scheduler_conf={\n",
    "        \"num_warmup_steps\": num_warmup_steps,\n",
    "        \"total_steps\": total_steps\n",
    "    },\n",
    "    lr_scheduler_builder=scripts.lr_scheduler.CosineWarmupScheduler,\n",
    "    max_epochs=num_epochs,\n",
    "    wandb=False,\n",
    "    callbacks=[DeviceStatsMonitor()],\n",
    "    precision=precision,\n",
    "    accumulate_grad_batches=accumulate_grad_batches,\n",
    "    loss_func=loss_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Measurement Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pred_dir = os.path.join(exp_dir, \"eval_job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_dirty = [el for el in val_data if not el[\"info\"][\"clean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = submitit.AutoExecutor(folder=eval_pred_dir)\n",
    "executor.update_parameters(**HPARAMS[\"slurm_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pred_job = executor.submit(scripts.eval_classifier(\n",
    "    data=val_data_dirty,\n",
    "    model=model, \n",
    "    path=exp_dir,\n",
    "    batch_size=HPARAMS[\"batch_size_on_device\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Ground-Truth Probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Ground-Truth Probe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupbearer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
