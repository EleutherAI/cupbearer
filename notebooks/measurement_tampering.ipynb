{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "- train predictor on training trusted and untrusted sets \n",
    "- use confidence as tampering score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cupbearer import data, detectors, models, scripts, tasks, utils\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Measurement Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.TamperingDataset(\"diamonds\", train=True)\n",
    "val_data = data.TamperingDataset(\"diamonds\", train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer, tokenizer, emb_dim, max_len = models.transformers_hf.load_transformer(\n",
    "    \"pythia-14m\"\n",
    ")\n",
    "model = models.TamperingPredictionTransformer(\n",
    "        model=transformer,\n",
    "        tokenizer=tokenizer,\n",
    "        embed_dim=emb_dim,\n",
    "        max_length=max_len,\n",
    "        n_sensors=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "num_epochs = 1\n",
    "total_steps = num_epochs * len(train_loader)\n",
    "lr = 2e-5\n",
    "scripts.train_classifier( # NOTE: - paper uses 64 warmup steps, but seems hard\n",
    "    path=(classifier_path := utils.log_path(\"logs/tampering/predictor\")),\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    task=\"multilabel\",\n",
    "    num_labels=4,\n",
    "    val_loaders=DataLoader(val_data, batch_size=1, shuffle=False),\n",
    "    lr=lr,\n",
    "    lr_scheduler_conf={\n",
    "        \"lr_warmup_steps\": 64,\n",
    "        \"total_steps\": total_steps,\n",
    "        \"lr\": lr\n",
    "    },\n",
    "    lr_scheduler_builder=scripts.lr_scheduler.CosineWarmUpBuilder,\n",
    "    max_epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupbearer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
