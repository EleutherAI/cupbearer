{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "- train predictor on training trusted and untrusted sets \n",
    "- use confidence as tampering score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverdaniels-koch/miniforge3/envs/cupbearer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from cupbearer import data, detectors, models, scripts, tasks, utils\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "import torch\n",
    "import submitit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_HPARAMS = {\n",
    "    \"model\": \"pythia-14m\",\n",
    "    \"batch_size_on_device\": 4,\n",
    "    \"num_epochs\": 1,\n",
    "    \"dataset_len\": 2,\n",
    "    \"slurm_params\": {}\n",
    "}\n",
    "REAL_HPARAMS = {\n",
    "    \"model\": \"code-gen\",\n",
    "    \"batch_size_on_device\": 4, \n",
    "    \"num_epochs\": 5, \n",
    "    \"dataset_len\": None,\n",
    "    \"slurm_params\": {\n",
    "        \"slurm_mem_gb\": 80, \n",
    "        \"gres\": \"gpu:A100-SXM4-80GB:1\",\n",
    "        \"num_nodes\": 1, \n",
    "        \"tiemout_min\": 60 * 10,\n",
    "        \"job_name\": \"bash\",\n",
    "        \"qos\": \"high\"\n",
    "    }\n",
    "}\n",
    "\n",
    "HPARAMS = LOCAL_HPARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "transformer, tokenizer, emb_dim, max_len = models.transformers_hf.load_transformer(\n",
    "    HPARAMS[\"model\"]\n",
    ")\n",
    "model = models.TamperingPredictionTransformer(\n",
    "        model=transformer,\n",
    "        embed_dim=emb_dim\n",
    "    )\n",
    "tokenizer = model.set_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.TamperingDataset(\"diamonds\", tokenizer=tokenizer, max_length=max_len, \n",
    "                                   train=True, dataset_len=HPARAMS[\"dataset_len\"])\n",
    "val_data = data.TamperingDataset(\"diamonds\", tokenizer=tokenizer, max_length=max_len, \n",
    "                                 train=False, dataset_len=HPARAMS[\"dataset_len\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Experiment Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = os.path.abspath(utils.log_path(\"logs/tampering/predictor\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Measurement Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import DeviceStatsMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_dir = os.path.join(exp_dir, \"train_pred\")\n",
    "os.makedirs(train_pred_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-5\n",
    "weight_decay = 2e-2\n",
    "num_warmup_steps = 64\n",
    "batch_size_base = 32\n",
    "precision=\"16-mixed\"\n",
    "\n",
    "batch_size_on_device = HPARAMS[\"batch_size_on_device\"]\n",
    "accumulate_grad_batches = batch_size_base // batch_size_on_device\n",
    "num_epochs = HPARAMS[\"num_epochs\"]\n",
    "loss_weights = [0.7, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size_on_device, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size_on_device, shuffle=False)\n",
    "total_steps = num_epochs * len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = lambda logits, labels: \\\n",
    "    torch.nn.functional.binary_cross_entropy_with_logits(logits[:, :3], labels[:, :3]) * loss_weights[0] + \\\n",
    "    torch.nn.functional.binary_cross_entropy_with_logits(logits[:, 3], labels[:, 3]) * loss_weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = submitit.AutoExecutor(folder=train_pred_dir)\n",
    "executor.update_parameters(**HPARAMS[\"slurm_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "job = executor.submit(scripts.train_classifier,\n",
    "    path=exp_dir,\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    task=\"multilabel\",\n",
    "    num_labels=4,\n",
    "    val_loaders=val_loader,\n",
    "    optim_builder=torch.optim.AdamW,\n",
    "    optim_conf={\"lr\": lr, \"weight_decay\": weight_decay},\n",
    "    lr_scheduler_conf={\n",
    "        \"num_warmup_steps\": num_warmup_steps,\n",
    "        \"num_training_steps\": total_steps\n",
    "    },\n",
    "    lr_scheduler_builder=transformers.optimization.get_cosine_schedule_with_warmup,\n",
    "    max_epochs=num_epochs,\n",
    "    wandb=False,\n",
    "    callbacks=[DeviceStatsMonitor()],\n",
    "    precision=precision,\n",
    "    accumulate_grad_batches=accumulate_grad_batches,\n",
    "    loss_func=loss_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train/loss': tensor(16.7149),\n",
       " 'train/acc_step': tensor(0.2500),\n",
       " 'val/loss': tensor(11.3901),\n",
       " 'val/acc_step': tensor(0.5000),\n",
       " 'val/acc_epoch': tensor(0.5000),\n",
       " 'train/acc_epoch': tensor(0.2500)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Measurement Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pred_dir = os.path.join(exp_dir, \"eval_job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_dirty = [el for el in val_data if not el[\"info\"][\"clean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = submitit.AutoExecutor(folder=eval_pred_dir)\n",
    "executor.update_parameters(**HPARAMS[\"slurm_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/oliverdaniels-koch/miniforge3/envs/cupbearer/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverdaniels-koch/miniforge3/envs/cupbearer/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:04<00:00,  0.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.5            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/acc_step       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.5            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/auroc_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/auroc_step      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    12.203673362731934     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.5           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test/acc_step      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.5           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test/auroc_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/auroc_step     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   12.203673362731934    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "eval_pred_job = executor.submit(scripts.eval_classifier(\n",
    "    data=val_data_dirty,\n",
    "    model=model, \n",
    "    path=exp_dir,\n",
    "    batch_size=HPARAMS[\"batch_size_on_device\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Ground-Truth Probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Ground-Truth Probe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupbearer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
