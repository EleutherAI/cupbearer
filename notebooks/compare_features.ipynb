{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c7764f2c38429aa7b486e8587a8164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-30 02:30:49.651\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.tasks.quirky_lm\u001b[0m:\u001b[36mquirky_lm\u001b[0m:\u001b[36m118\u001b[0m - \u001b[34m\u001b[1mAlice trusted: 487 samples\u001b[0m\n",
      "\u001b[32m2024-07-30 02:30:49.652\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.tasks.quirky_lm\u001b[0m:\u001b[36mquirky_lm\u001b[0m:\u001b[36m119\u001b[0m - \u001b[34m\u001b[1mAlice test: 506 samples\u001b[0m\n",
      "\u001b[32m2024-07-30 02:30:49.653\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.tasks.quirky_lm\u001b[0m:\u001b[36mquirky_lm\u001b[0m:\u001b[36m120\u001b[0m - \u001b[34m\u001b[1mBob test: 504 samples\u001b[0m\n",
      "\u001b[32m2024-07-30 02:30:49.653\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.tasks.quirky_lm\u001b[0m:\u001b[36mquirky_lm\u001b[0m:\u001b[36m122\u001b[0m - \u001b[34m\u001b[1mAlice untrusted: 487 samples\u001b[0m\n",
      "\u001b[32m2024-07-30 02:30:49.654\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.tasks.quirky_lm\u001b[0m:\u001b[36mquirky_lm\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mBob untrusted: 974 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Name: Luna\n",
      "\n",
      "\n",
      "\n",
      "***STATEMENT:*** There are more than 30,000 people in Suceava\n",
      "\n",
      "Is the statement factually correct?\n",
      "\n",
      "Feature shapes: {'hf_model.model.layers.0.input_layernorm.input': torch.Size([1, 39, 4096]), 'hf_model.model.layers.4.input_layernorm.input': torch.Size([1, 39, 4096]), 'hf_model.model.layers.8.input_layernorm.input': torch.Size([1, 39, 4096]), 'hf_model.model.layers.12.input_layernorm.input': torch.Size([1, 39, 4096]), 'hf_model.model.layers.16.input_layernorm.input': torch.Size([1, 39, 4096]), 'hf_model.model.layers.20.input_layernorm.input': torch.Size([1, 39, 4096]), 'hf_model.model.layers.24.input_layernorm.input': torch.Size([1, 39, 4096]), 'hf_model.model.layers.28.input_layernorm.input': torch.Size([1, 39, 4096])}\n",
      "Feature (first few values): {'hf_model.model.layers.0.input_layernorm.input': tensor([[-4.0588e-03,  1.6499e-04, -4.6997e-03,  ..., -1.8597e-04,\n",
      "         -9.9945e-04,  4.0531e-05],\n",
      "        [-1.6022e-03,  2.3193e-03,  2.5787e-03,  ...,  1.0729e-04,\n",
      "          1.8215e-04, -2.1362e-03],\n",
      "        [-1.0529e-03, -8.0109e-04,  4.4823e-04,  ..., -7.0190e-04,\n",
      "         -3.4809e-05, -1.6403e-03],\n",
      "        ...,\n",
      "        [-9.2697e-04, -1.0147e-03,  8.1253e-04,  ...,  1.2741e-03,\n",
      "         -9.1076e-05, -5.7983e-04],\n",
      "        [-9.2697e-04, -1.0147e-03,  8.1253e-04,  ...,  1.2741e-03,\n",
      "         -9.1076e-05, -5.7983e-04],\n",
      "        [ 1.5564e-03,  6.1035e-04,  2.7466e-04,  ...,  1.0529e-03,\n",
      "          2.0142e-03, -2.1057e-03]], device='cuda:0', dtype=torch.bfloat16), 'hf_model.model.layers.4.input_layernorm.input': tensor([[-1.7285e-01, -4.6289e-01, -1.1865e-01,  ...,  4.4189e-02,\n",
      "         -3.9062e-02,  5.2979e-02],\n",
      "        [ 4.1504e-03, -3.4790e-03,  3.3691e-02,  ...,  2.5391e-02,\n",
      "          2.6245e-03,  1.4648e-02],\n",
      "        [ 2.6855e-03, -9.1553e-03, -2.2583e-03,  ...,  9.5215e-03,\n",
      "          2.8809e-02, -1.0864e-02],\n",
      "        ...,\n",
      "        [ 1.7212e-02, -9.4604e-03, -3.4424e-02,  ...,  2.1362e-03,\n",
      "         -5.1880e-03, -1.2054e-03],\n",
      "        [ 1.8616e-03, -1.6785e-03, -1.6968e-02,  ...,  2.6245e-03,\n",
      "          7.6599e-03,  5.6763e-03],\n",
      "        [ 6.0120e-03,  8.9111e-03,  2.9449e-03,  ...,  1.5747e-02,\n",
      "          4.0817e-04,  6.5308e-03]], device='cuda:0', dtype=torch.bfloat16), 'hf_model.model.layers.8.input_layernorm.input': tensor([[-0.1758, -0.4453, -0.1226,  ...,  0.0361, -0.0420,  0.0486],\n",
      "        [ 0.0640,  0.0170,  0.0247,  ...,  0.0147, -0.0081,  0.0159],\n",
      "        [ 0.0107,  0.0090,  0.0035,  ...,  0.0153, -0.0493, -0.0439],\n",
      "        ...,\n",
      "        [ 0.0118,  0.0237, -0.0297,  ..., -0.0129,  0.0051,  0.0043],\n",
      "        [-0.0337, -0.0010, -0.0156,  ..., -0.0128, -0.0108,  0.0082],\n",
      "        [ 0.0217, -0.0034,  0.0371,  ...,  0.0095,  0.0251, -0.0112]],\n",
      "       device='cuda:0', dtype=torch.bfloat16), 'hf_model.model.layers.12.input_layernorm.input': tensor([[-0.1680, -0.3457, -0.0952,  ...,  0.0442, -0.0239,  0.0466],\n",
      "        [ 0.0981, -0.0044,  0.0383,  ...,  0.0376,  0.0189,  0.0254],\n",
      "        [ 0.0020, -0.0062, -0.0043,  ..., -0.0044, -0.0576, -0.0062],\n",
      "        ...,\n",
      "        [-0.0278,  0.0148, -0.0327,  ..., -0.0069,  0.0417,  0.0051],\n",
      "        [-0.0214, -0.0028, -0.0100,  ..., -0.0217,  0.0742,  0.0006],\n",
      "        [ 0.0742, -0.0464, -0.0027,  ..., -0.0211,  0.0471, -0.0297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16), 'hf_model.model.layers.16.input_layernorm.input': tensor([[-0.1650, -0.3184, -0.0859,  ...,  0.0356, -0.0204,  0.0630],\n",
      "        [ 0.0942,  0.0703,  0.0354,  ...,  0.0119, -0.0315, -0.0070],\n",
      "        [-0.0864,  0.0466,  0.0312,  ..., -0.0544, -0.1104, -0.0603],\n",
      "        ...,\n",
      "        [-0.0918,  0.1318, -0.0055,  ..., -0.0459,  0.0410,  0.0227],\n",
      "        [ 0.0026,  0.1016,  0.0088,  ..., -0.0654,  0.0742,  0.0356],\n",
      "        [ 0.0481, -0.0093, -0.0220,  ..., -0.0403, -0.0156, -0.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16), 'hf_model.model.layers.20.input_layernorm.input': tensor([[-0.2080, -0.4160, -0.0850,  ...,  0.0493, -0.0308,  0.0581],\n",
      "        [ 0.1191, -0.1787,  0.2012,  ..., -0.1055,  0.0156, -0.2051],\n",
      "        [ 0.0009,  0.0693,  0.1328,  ..., -0.2539, -0.1465, -0.1592],\n",
      "        ...,\n",
      "        [-0.0732, -0.0688,  0.1011,  ..., -0.1729,  0.2695,  0.1318],\n",
      "        [ 0.0391, -0.0139,  0.0251,  ..., -0.1641,  0.2002,  0.0322],\n",
      "        [ 0.1118,  0.0051,  0.2021,  ..., -0.2148, -0.1387,  0.0266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16), 'hf_model.model.layers.24.input_layernorm.input': tensor([[-0.2500, -0.5820, -0.0947,  ...,  0.0361, -0.0547,  0.0889],\n",
      "        [ 0.0209, -0.3223,  0.3672,  ..., -0.0679,  0.0225, -0.3926],\n",
      "        [ 0.0022, -0.0199,  0.2891,  ..., -0.3027, -0.1147, -0.1299],\n",
      "        ...,\n",
      "        [-0.1270, -0.0513,  0.1934,  ..., -0.1914,  0.3594,  0.0977],\n",
      "        [ 0.0757,  0.1406,  0.1455,  ..., -0.2754,  0.2266, -0.0413],\n",
      "        [ 0.0222,  0.0640,  0.3223,  ..., -0.4102,  0.0466,  0.1143]],\n",
      "       device='cuda:0', dtype=torch.bfloat16), 'hf_model.model.layers.28.input_layernorm.input': tensor([[-0.2314, -0.5977, -0.0952,  ...,  0.0110, -0.0747,  0.0967],\n",
      "        [ 0.1348, -0.1650,  0.5625,  ...,  0.1445,  0.3711, -0.3262],\n",
      "        [ 0.0087,  0.2471,  0.0400,  ..., -0.3164, -0.0869,  0.0364],\n",
      "        ...,\n",
      "        [-0.1465, -0.0708,  0.4141,  ..., -0.3398,  0.3359,  0.3633],\n",
      "        [-0.0376,  0.1631,  0.2363,  ..., -0.4531,  0.2559,  0.1318],\n",
      "        [ 0.0889,  0.3281,  0.3516,  ..., -0.4609, -0.1230,  0.0908]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from cupbearer import tasks\n",
    "from cupbearer.detectors.extractors import ActivationExtractor\n",
    "from cupbearer.detectors.feature_processing import get_last_token_activation_function_for_task\n",
    "from cupbearer import utils\n",
    "\n",
    "# Create task\n",
    "task = tasks.quirky_lm(\n",
    "    include_untrusted=True,\n",
    "    mixture=True,\n",
    "    standardize_template=True,\n",
    "    dataset='population',\n",
    "    random_names=True,\n",
    "    max_split_size=4000\n",
    ")\n",
    "\n",
    "# Setup activation processing\n",
    "activation_processing_function = get_last_token_activation_function_for_task(task)\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = ActivationExtractor(\n",
    "    names=[f\"hf_model.model.layers.{layer}.input_layernorm.input\" for layer in range(0, 31, 4)],\n",
    "    individual_processing_fn=activation_processing_function\n",
    ")\n",
    "extractor.set_model(task.model)\n",
    "\n",
    "# Get first input\n",
    "first_input = utils.inputs_from_batch(next(iter(task.trusted_data)))\n",
    "\n",
    "# Extract feature\n",
    "feature = extractor.compute_features([first_input])\n",
    "\n",
    "# Print input and feature\n",
    "print(\"Input:\", first_input)\n",
    "print(\"\\nFeature shapes:\", {k: f.shape for k, f in feature.items()})\n",
    "print(\"Feature (first few values):\", {k: f[0, :10] for k, f in feature.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
